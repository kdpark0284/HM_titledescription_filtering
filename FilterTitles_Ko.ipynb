{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kdpark0284/HM_titledescription_filtering/blob/testing1/FilterTitles_Ko.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDYLTRK_Ia7t"
      },
      "source": [
        "# KoNLPy Start Up With Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbZlVXbsIjWx"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "UnUCE2weGmi_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7924e306-614f-4956-a0a4-27b69926d812"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Ign:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,421 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,393 kB]\n",
            "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [861 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,130 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,115 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,785 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,217 kB]\n",
            "Get:20 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,552 kB]\n",
            "Fetched 21.9 MB in 7s (3,141 kB/s)\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "Package python-dev is not available, but is referred to by another package.\n",
            "This may mean that the package is missing, has been obsoleted, or\n",
            "is only available from another source\n",
            "However the following packages replace it:\n",
            "  python2-dev python2 python-dev-is-python3\n",
            "\n",
            "Collecting JPype1\n",
            "  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1) (24.1)\n",
            "Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 488.6/488.6 kB 12.3 MB/s eta 0:00:00\n",
            "Installing collected packages: JPype1\n",
            "Successfully installed JPype1-1.5.0\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.5.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.1)\n",
            "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.4/19.4 MB 64.9 MB/s eta 0:00:00\n",
            "Installing collected packages: konlpy\n",
            "Successfully installed konlpy-0.6.0\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading rapidfuzz-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 39.5 MB/s eta 0:00:00\n",
            "Installing collected packages: rapidfuzz\n",
            "Successfully installed rapidfuzz-3.9.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "E: Package 'python-dev' has no installation candidate\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "apt-get update\n",
        "apt-get install g++ openjdk-8-jdk python-dev python3-dev\n",
        "pip3 install JPype1\n",
        "pip3 install konlpy\n",
        "pip install openpyxl\n",
        "pip install rapidfuzz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ebaapQPkGvqY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b095626d-7d04-48e3-f73d-128fb26f895d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"\n"
          ]
        }
      ],
      "source": [
        "%env JAVA_HOME \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqjFwgcOMeT9"
      },
      "source": [
        "### Install Mecab (Takes 5min+ usually)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_Ni_MNbyMdox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08687832-8cfe-4aa0-d584-a93f2444b010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 138, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 138 (delta 26), reused 22 (delta 8), pack-reused 91\u001b[K\n",
            "Receiving objects: 100% (138/138), 1.72 MiB | 24.06 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "v5cjuboiGFDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de046ecb-0575-47b9-dbe9-ef0892a31086"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Mecab-ko-for-Google-Colab\n"
          ]
        }
      ],
      "source": [
        "cd Mecab-ko-for-Google-Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5rUcLbWEGFsU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44082a9d-7df2-416b-f788-26af2eb548d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing konlpy.....\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.5.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.1)\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2024-08-01 01:14:44--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 185.166.143.49, 185.166.143.50, 185.166.143.48, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|185.166.143.49|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNGG6B77E5&Signature=qpLuZdDOoKLhLZqOIxOQ630VogI%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEIL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQDHqqVi4UZXBrR9937xO7y6ODswnqxERPbDt%2FgLnTlSewIgY8BJVPwpg%2BFEDwhPhNTvqhj03lnZn7OjPNKnWhv579AqpwIIahAAGgw5ODQ1MjUxMDExNDYiDOG1vcQEQSdrJHZMtSqEAj4Ov%2B%2BvThuvQTUOjLKl%2Bo4q0DcDOqnmzu%2F0TihEkbr4QUiw5mR7XEeCGB2T6wUnMxRm8Gqy%2BmdaUs3k9XOrBuLhg4jVpPeKenh3fATTDgYcVPfyczIEGvGZnPc7v7SwX41rroL5qaWIzvDA2J0%2Fdg8ZW7kqko636H6Jd8ytNGamnVLeGmqc3yl%2Fk6rLljC3nL%2FCAoDNFLX8K04s7ZJPdwVjVUU%2FwrLyWiZ50C3EUlxGgUPPUF7AJX%2F2L3E3owxLpGy4fGcc0S9qbEVmMjdbPJ3M4Or4Z7HqQJ7z9gUJyPbYlxkSGHUoo5MaQERFCQq7Nfmu2rFb1nqjAjZofdJ4AEm45jlBMJi%2Fq7UGOp0Bs4Bz8T0KqG7I5l%2BJJeK9qDP0AXZkZHlmhJVhOM1JS02LZNs3YTQSJ73jqaDiQoHGfmf2HulIhog2ybW88jiWuiVa7Asim9h1Fr5X9tFF9KFZf0V7WVSOr7pmTZ8YXCoDaR%2FGVcy5o%2FVH4ACePFVTKTXm69ygTGzGJM1irv0XArguWSK0NlTmohqVrHGUO6nnxxPVdO%2BdNRKVYo5Qeg%3D%3D&Expires=1722476192 [following]\n",
            "--2024-08-01 01:14:45--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNGG6B77E5&Signature=qpLuZdDOoKLhLZqOIxOQ630VogI%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEIL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQDHqqVi4UZXBrR9937xO7y6ODswnqxERPbDt%2FgLnTlSewIgY8BJVPwpg%2BFEDwhPhNTvqhj03lnZn7OjPNKnWhv579AqpwIIahAAGgw5ODQ1MjUxMDExNDYiDOG1vcQEQSdrJHZMtSqEAj4Ov%2B%2BvThuvQTUOjLKl%2Bo4q0DcDOqnmzu%2F0TihEkbr4QUiw5mR7XEeCGB2T6wUnMxRm8Gqy%2BmdaUs3k9XOrBuLhg4jVpPeKenh3fATTDgYcVPfyczIEGvGZnPc7v7SwX41rroL5qaWIzvDA2J0%2Fdg8ZW7kqko636H6Jd8ytNGamnVLeGmqc3yl%2Fk6rLljC3nL%2FCAoDNFLX8K04s7ZJPdwVjVUU%2FwrLyWiZ50C3EUlxGgUPPUF7AJX%2F2L3E3owxLpGy4fGcc0S9qbEVmMjdbPJ3M4Or4Z7HqQJ7z9gUJyPbYlxkSGHUoo5MaQERFCQq7Nfmu2rFb1nqjAjZofdJ4AEm45jlBMJi%2Fq7UGOp0Bs4Bz8T0KqG7I5l%2BJJeK9qDP0AXZkZHlmhJVhOM1JS02LZNs3YTQSJ73jqaDiQoHGfmf2HulIhog2ybW88jiWuiVa7Asim9h1Fr5X9tFF9KFZf0V7WVSOr7pmTZ8YXCoDaR%2FGVcy5o%2FVH4ACePFVTKTXm69ygTGzGJM1irv0XArguWSK0NlTmohqVrHGUO6nnxxPVdO%2BdNRKVYo5Qeg%3D%3D&Expires=1722476192\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 16.182.97.233, 54.231.228.249, 52.216.209.161, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|16.182.97.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  2.63MB/s    in 0.5s    \n",
            "\n",
            "2024-08-01 01:14:46 (2.63 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2024-08-01 01:16:58--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 185.166.143.49, 185.166.143.48, 185.166.143.50, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|185.166.143.49|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNLIEGTPWQ&Signature=q2h7dudeUTrJsQ9ApGcvFkl79gQ%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEIH%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIGa8DnNIROQ0jOi%2BAGg8O6AC7B8WGrAQZuJDB3sapgSmAiBce1b4yEFjoFDXSzjGGZPJ%2FXFyi4o9m%2FICih0%2FoFKSjyqnAghqEAAaDDk4NDUyNTEwMTE0NiIMIzI9MdWyQMEta4LyKoQC4pvrSxfnPLQJrGXOhKPXpn572Fv5oU82qrrMeVW5WAdsENTXBjQ4VLPeg88vowovsEnZrbjviDm0K9wpLJbvWHYGJrjdgrKq3wct3aAQFIUze1Q8CCSeo5n0APK8G52eP%2Bb1WCjPIXiiTPwSJ4O3WALWOO53C4CsUbPitgKO9bCL0Ceq8VO90cMtvabxbNB6VZdnQDcvjKSx0mi4cD0bXuWue7tSClpF%2BBm4LLiIFPDHqAzTYcEtW6P7f6s1zHF8oxUndMrFUGTcb3B0WhPhtNRSp17FE9PQ2xt5TtZCJcGf4sRhG4qLPs3JYsPabDymuzrxKjSfq725qQYTEnQ7tA%2By1sEwxL2rtQY6ngEchsfvWMrQIjv80vyF71397JY9PtTVWsDLMYOP2stInN4aNEVTVSLDpp4B1ZiL1yhkI8Hr32VQID4QJVotVNmKj5EikDZZpxn3hvdaibZosLQMAbCs6mi06fNjw1eHUqqgdtAt1XC0zZ8kmkYbPgymrIEjPwemPYzV3QbXgrTZa1vK7oPYOlxMIBxhdnq09szR%2FSaIphqgBInIu1FpVQ%3D%3D&Expires=1722475980 [following]\n",
            "--2024-08-01 01:16:59--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNLIEGTPWQ&Signature=q2h7dudeUTrJsQ9ApGcvFkl79gQ%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEIH%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIGa8DnNIROQ0jOi%2BAGg8O6AC7B8WGrAQZuJDB3sapgSmAiBce1b4yEFjoFDXSzjGGZPJ%2FXFyi4o9m%2FICih0%2FoFKSjyqnAghqEAAaDDk4NDUyNTEwMTE0NiIMIzI9MdWyQMEta4LyKoQC4pvrSxfnPLQJrGXOhKPXpn572Fv5oU82qrrMeVW5WAdsENTXBjQ4VLPeg88vowovsEnZrbjviDm0K9wpLJbvWHYGJrjdgrKq3wct3aAQFIUze1Q8CCSeo5n0APK8G52eP%2Bb1WCjPIXiiTPwSJ4O3WALWOO53C4CsUbPitgKO9bCL0Ceq8VO90cMtvabxbNB6VZdnQDcvjKSx0mi4cD0bXuWue7tSClpF%2BBm4LLiIFPDHqAzTYcEtW6P7f6s1zHF8oxUndMrFUGTcb3B0WhPhtNRSp17FE9PQ2xt5TtZCJcGf4sRhG4qLPs3JYsPabDymuzrxKjSfq725qQYTEnQ7tA%2By1sEwxL2rtQY6ngEchsfvWMrQIjv80vyF71397JY9PtTVWsDLMYOP2stInN4aNEVTVSLDpp4B1ZiL1yhkI8Hr32VQID4QJVotVNmKj5EikDZZpxn3hvdaibZosLQMAbCs6mi06fNjw1eHUqqgdtAt1XC0zZ8kmkYbPgymrIEjPwemPYzV3QbXgrTZa1vK7oPYOlxMIBxhdnq09szR%2FSaIphqgBInIu1FpVQ%3D%3D&Expires=1722475980\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.234.57, 3.5.8.160, 52.217.108.132, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.234.57|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  21.2MB/s    in 2.2s    \n",
            "\n",
            "2024-08-01 01:17:01 (21.2 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/v0.6.0/scripts/mecab.sh)\n",
            "https://github.com/konlpy/konlpy/issues/395#issue-1099168405 - 2022.01.11\n",
            "Done\n",
            "Install mecab-python\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n",
            "light 버전 작성 : Dogdriip님 ( https://github.com/Dogdriip )\n",
            "문제를 해결해주신 combacsa님 감사합니다.\n"
          ]
        }
      ],
      "source": [
        "!bash install_mecab-ko_on_colab_light_220429.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26qSuqNbIpiq"
      },
      "source": [
        "## (Test before using KoNLPy) -- Not Neccesary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTA-zty1HZ1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ee4ba69-a542-466a-e839-43e634a7c3f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "python3 -c \"import jpype; jpype.startJVM(convertStrings=True); print(jpype.isJVMStarted())\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ei-S5_6ZHrYP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06d1f221-2a16-4988-9f01-0fd79fe7144e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (7.4.4)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest) (24.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest) (1.2.2)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest) (2.0.1)\n",
            "======================================= test session starts ========================================\n",
            "platform linux -- Python 3.10.12, pytest-7.4.4, pluggy-1.5.0 -- /usr/bin/python3\n",
            "cachedir: .pytest_cache\n",
            "rootdir: /tmp/test-hfa1gHRHU1\n",
            "plugins: typeguard-4.3.0, anyio-3.7.1\n",
            "collecting ... collected 37 items\n",
            "\n",
            "../../tmp/test-hfa1gHRHU1/test/test_corpus.py::test_corpus_kolaw PASSED                      [  2%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_hannanum.py::test_hannanum_analyze PASSED                [  5%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_hannanum.py::test_hannanum_nouns PASSED                  [  8%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_hannanum.py::test_hannanum_morphs PASSED                 [ 10%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_hannanum.py::test_hannanum_pos_9 PASSED                  [ 13%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_hannanum.py::test_hannanum_pos_22 PASSED                 [ 16%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_hannanum.py::test_hannanum_pos_join PASSED               [ 18%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_hannanum.py::test_hannanum_typechecking PASSED           [ 21%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_kkma.py::test_kkma_nouns PASSED                          [ 24%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_kkma.py::test_kkma_morphs PASSED                         [ 27%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_kkma.py::test_kkma_pos PASSED                            [ 29%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_kkma.py::test_kkma_pos_join PASSED                       [ 32%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_kkma.py::test_kkma_sentences PASSED                      [ 35%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_kkma.py::test_kkma_typechecking PASSED                   [ 37%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_komoran.py::test_komoran_nouns PASSED                    [ 40%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_komoran.py::test_komoran_pos PASSED                      [ 43%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_komoran.py::test_komoran_pos_join PASSED                 [ 45%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_komoran.py::test_komoran_morphs PASSED                   [ 48%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_komoran.py::test_komoran_typechecking PASSED             [ 51%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_mecab.py::test_mecab_pos_43 PASSED                       [ 54%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_mecab.py::test_mecab_pos_join PASSED                     [ 56%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_mecab.py::test_mecab_morphs PASSED                       [ 59%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_mecab.py::test_mecab_nouns PASSED                        [ 62%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_mecab.py::test_mecab_typechecking PASSED                 [ 64%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_openkoreantext.py::test_tkorean_pos PASSED               [ 67%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_openkoreantext.py::test_tkorean_pos_1 PASSED             [ 70%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_openkoreantext.py::test_tkorean_pos_2 PASSED             [ 72%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_openkoreantext.py::test_tkorean_pos_3 PASSED             [ 75%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_openkoreantext.py::test_tkorean_pos_join PASSED          [ 78%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_openkoreantext.py::test_tkorean_nouns PASSED             [ 81%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_openkoreantext.py::test_tkorean_phrases PASSED           [ 83%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_openkoreantext.py::test_tkorean_morphs PASSED            [ 86%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_openkoreantext.py::test_tkorean_normalize PASSED         [ 89%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_openkoreantext.py::test_tkorean_typechecking PASSED      [ 91%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_utils.py::test_utils_pprint PASSED                       [ 94%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_utils.py::test_utils_concordance PASSED                  [ 97%]\n",
            "../../tmp/test-hfa1gHRHU1/test/test_utils.py::test_utils_concordance_show PASSED             [100%]\n",
            "\n",
            "======================================= 37 passed in 59.60s ========================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into '/tmp/test-hfa1gHRHU1'...\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "pip3 install pytest\n",
        "TEST_DIR=$(mktemp -d -t test-XXXXXXXXXX)\n",
        "git clone https://github.com/konlpy/konlpy --depth=1 $TEST_DIR\n",
        "python3 -m pytest -v $TEST_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX85aTLQLbIW"
      },
      "source": [
        "## Use KoNLPy Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1my-kYf6LdHa"
      },
      "outputs": [],
      "source": [
        "# import konlpy\n",
        "# from konlpy.tag import Kkma, Komoran, Hannanum, Okt\n",
        "# from konlpy.utils import pprint\n",
        "# kkma = Kkma()\n",
        "# komoran = Komoran()\n",
        "# hannanum = Hannanum()\n",
        "# okt = Okt()\n",
        "# pprint(kkma.sentences(u'네, 안녕하세요. 반갑습니다.'))\n",
        "# pprint(komoran.nouns(u'질문이나 건의사항은 깃헙 이슈 트래커에 남겨주세요.'))\n",
        "# pprint(hannanum.pos(u'오류보고는 실행환경, 에러메세지와함께 설명을 최대한상세히!^^'))\n",
        "# pprint(okt.phrases(u'구글은 멋져요. 깃허브도 멋져요. KoNLPy도 멋져요!'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the installation of Mecab was successful, the code below will run well."
      ],
      "metadata": {
        "id": "YwulPsdIW3eK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLFpnE9cLsod"
      },
      "outputs": [],
      "source": [
        "# import konlpy\n",
        "# from konlpy.utils import pprint\n",
        "# from konlpy.tag import Mecab\n",
        "# from konlpy.utils import pprint\n",
        "\n",
        "# mecab = Mecab()\n",
        "\n",
        "# text = \"삼성 갤럭시 탭 s8 울트라(6GB+1TB)스페이스블랙[자급제]\"\n",
        "# mecabnouns = mecab.nouns(text)\n",
        "# print(\"Mecab Nouns:\", mecabnouns)\n",
        "# mecabmorphs = mecab.morphs(text)\n",
        "# print(\"Mecab Morphs:\", mecabmorphs)\n",
        "# type(mecabmorphs)\n",
        "\n",
        "# # mecab.tagset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh5WDHYaV5QW"
      },
      "source": [
        "# Extraction Process (Read files, Extract Relevant Words)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## File Upload, Load Dependencies"
      ],
      "metadata": {
        "id": "Pe0fSlwybO5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import openpyxl\n",
        "from konlpy.tag import Mecab\n",
        "from konlpy.utils import pprint\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "from rapidfuzz import fuzz, process\n",
        "import io\n",
        "mecab = Mecab()\n",
        "uploaded_file = files.upload ()\n",
        "\n",
        "\"\"\"\n",
        "Excel 파일 업로드를 해주세요.\n",
        "Please upload an Excel file.\n",
        "\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "DlBYzsdqa3wR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "881aef93-df8a-4be7-a5ae-444702d10d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bd354910-974a-454f-858e-49ad7fc3b8f2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bd354910-974a-454f-858e-49ad7fc3b8f2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving HOMEAPPLIANCE_COLLECTION.xlsx to HOMEAPPLIANCE_COLLECTION.xlsx\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nExcel 파일 업로드를 해주세요.\\nPlease upload an Excel file.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 업로드된 파일 이름 가져오기\n",
        "file_name = next(iter(uploaded_file))\n",
        "\n",
        "# 업로드된 파일을 데이터프레임으로 읽기\n",
        "df = pd.read_excel(io.BytesIO(uploaded_file[file_name]))"
      ],
      "metadata": {
        "id": "qznYSKFz7Qy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "기존에는 단어를 최소단위로 하여 필요한 요소를 추출했지만 띄어쓰기, 포맷등의 문제가 엃혀 필요한 단어를 파이썬에서 읽게 하는것이 힘들었음.\n",
        "\n",
        "MeCab이라는 한국어 형태소 분석 라이브러리를 사용하여 한국어의 최소단위인 형태소를 기반으로 제목, 용량, 색상을 추출하고자 함."
      ],
      "metadata": {
        "id": "ZwUt98C_LZGO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter Lists"
      ],
      "metadata": {
        "id": "KLbna32b1bD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "product_title = [\n",
        "                '갤럭시탭', '갤럭시노트', '갤럭시버즈','아이폰', '갤럭시', '프로', '울트라', '맥스', '아이패드', '에어팟', '플립', '폴드', '뮤패드', 'FE', 'FE+'\n",
        "                '북', '맥북', 'S', 'Ultra', 'M1', 'M2', 'M3', 'M4', 'M5', 'Pro', 'ProMax', 'A', 'Tab', '맥', '미니', '북', '아이맥', '플러스',\n",
        "                'Galaxy', 'iPhone', 'iPad', 'MacBook', 'Zenbook', '그램', '에어', '스타일', '프로맥스', '미패드', 'Air', '탭', '노트', '버즈', '패드', 'AirPods',\n",
        "                'Flip', 'Fold', 'MuPad', 'FE', 'FE+', 'Lite', '서피스', '고', '울트라북', '스튜디오', '베이직'\n",
        "                  ]\n",
        "\n",
        "product_type_dict = {\n",
        "                      \"pc\" : \"IT\",\n",
        "                      \"mobilephone\" : \"IT\",\n",
        "                      \"tablet\" : \"IT\",\n",
        "                      \"laptop\" : \"IT\",\n",
        "}\n",
        "\n",
        "type_code_name = {\n",
        "    'refrigerator': '냉장고',\n",
        "    'refrigeratorsingledoor': '싱글도어냉장고',\n",
        "    'refrigeratortwodoor': '투도어냉장고',\n",
        "    'washingmachine': '세탁기',\n",
        "    'airconditioner': '에어컨',\n",
        "    'ricecooker':     '밥솥',\n",
        "    'vacuumcleaner':  '청소기',\n",
        "    'dishwasher':     '식기세척기',\n",
        "    'oven':           '오븐',\n",
        "    'microwave':      '전자레인지',\n",
        "    'coffeemachine':  '커피머신',\n",
        "    'kimchirefrigerator': '김치냉장고',\n",
        "    'dryer':          '건조기',\n",
        "    'airpurifier':    '공기청정기',\n",
        "    'razor':            '면도기',\n",
        "    'waterpurifier':   '정수기',\n",
        "    'monitor':          '모니터'\n",
        "    # 필요한 만큼 더 추가\n",
        "}\n",
        "\n",
        "color_list = [\"문스톤그레이\", \"스페이스 그레이\", \"코스믹 그레이\", \"내추럴\", \"카밍 차콜\", \"카밍그린\", \"오로라화이트\", \"잉크웰그레이\",\n",
        "              \"스노우화이트\", \"새틴 화이트\", \"프라임 실버\", \"라벤더\", \"스페이스그레이\", \"루미다크실버\", \"미드나이트\", \"플래티넘실버\",\n",
        "              \"스페이스 블랙\", \"그라파이트\", \"매트블랙\", \"사파이어\", \"스타라이트\", \"이클립스그레이\", \"새틴화이트\", \"보라퍼플\",\n",
        "              \"글램화이트\", \"네이비블루\", \"메탈릭실버\", \"화이트실버\", \"카밍베이지\", \"페블 그레이\", \"블랙 메탈\", \"코타 화이트\",\n",
        "              \"코타 퍼플\", \"크림라벤더\", \"크림 화이트\", \"크림화이트\", \"코타 차콜\", \"실버글라스\", \"블랙 크롬메탈\", \"샤인베이지\",\n",
        "              \"에센셜화이트\", \"카밍그린\", \"크림레몬\", \"크림 그레이\", \"스페이스블랙\", \"실키크림\", \"샴페인골드\", \"실키오트밀\",\n",
        "              \"크림그레이\", \"다크그레이\", \"모닝 블루\", \"그레이스화이트\", \"미스티 화이트\", \"에센셜 블루 그레이\", \"옥스포드그레이\",\n",
        "              \"카밍클레이브라운\", \"사틴 차콜\", \"베르사유그레이\", \"매트블랙\", \"미스티라일락\", \"보타닉그린\", \"코튼플라워\", \"팬텀블랙\", \"시나모롤\", \"크림\",\n",
        "              \"라이트블루\", \"다크레드\", \"라이트그린\", \"라임\", \"핑크골드\", \"딥퍼플\", \"화이트 티타늄\", \"블루 티타늄\", \"블랙 티타늄\", \"내추럴 티타늄\",\n",
        "              \"실버\", \"베이지\", \"블랙\", \"화이트\", \"블루\", \"바이올렛\", \"옐로우\", \"그레이\", \"민트\", \"그린\", \"핑크\", \"퍼플\", \"차콜\", \"플래티넘\", \"옐로\", \"골드\", \"레드\",\n",
        "              \"Black\", \"White\", \"Red\", \"Blue\", \"Green\", \"Yellow\", \"Pink\", \"Gray\", \"Silver\", \"Spacegray\", \"그레이그린\"]\n",
        "\n",
        "general_stopwords_list = [ '에듀몰', '해피투게딜', '자급제', '재고보유', '하이마트배송!', 'WQXGA +', '30만원대', '개별구매불가', '본체만구매', '자동취소',\n",
        "                        '하이마트배송', '스태킹키트 포함', '스태킹키트 미포함', '한정판매', '한정수량', '온라인 전용', '1주이상소요/클리어런스', '스태킹/앵글',\n",
        "                        '셀프관리형', '신모델', '즉시배송', '신상', '앵글설치포함,별도비용발생', '하이마트 설치', '최대36개월무', '사은품 증정', '제주마지막1대', '직렬설치',\n",
        "                        '추가 다운로드 쿠폰', '국내정발', '빠른출발', '진열', '맞춤출수', '전시', '주연테크x하이메이드', '사내판매', '스태킹키트', '카드 추가',\n",
        "                        '본품', '배송지연', '6개월주기 방문관리형', '익일배송', 'UP가전', '특가', '뭉치면싸다', '1만 다운로드 쿠폰', '1주차', '발송예정', '스태킹설치',\n",
        "                        '사용안함', '스마트픽',  '미디어', '인버터', '정품OS', '단순배송', '2만원할인', '100원딜', '10대', '한정', '단독!', '단독', '추가 카드',\n",
        "                        'AppleCare+', '1주이상소요', '**',  'DDR5', 'DDR4', 'DDR6', '시력보호', '최신형', '운영', '스태이션 포함!', '추가 쿠폰', '스태킹', '앵글',\n",
        "                        '최종321만', '10대 한정판매',  '출고', '안드로이드', '배송시간 소요', '방문관리', 'i5.*?', 'i7.*?', 'win11', '20만원대', '링크!', '키트',\n",
        "                        '사은품 증정', '2주이상 소요', '동시구매행사용', '1만원할인', '할인', '신학기특가', '키트포함', '키트 포함', 'CPU', 'GPU', 'RTX', 'GTX',\n",
        "                        '각도조절형', '해피투게딜이벤트', '서랍형', '36개월케어십포함', '개별구매불가,본체만구매-자동취소', '전국무료설치', '8코어', '12코어', '16코어', '10코어',\n",
        "                        '한정수량', '단종', '소진', '특가', '포토상품평이벤트', '어메이징','3월', '4월', '5월', '6월', '7월', '2주이상소요', '3주이상소요', 'NEW', '가벼운',\n",
        "                        '8월', '9월', '10월', '11월', '12월', '1월', '2월', '행사', '1등급', '당질저감', '벽걸이조절형', '3년케어십', '초고온수', '기획전', '미포함', '포함',\n",
        "                        '음성인식', '청정바람', '자가관리', '셀프형', '6개월', '방문주기', '시크릿 !', '최대', '10%', '신모델', '공동구매', '하이마트', '1만 다운로드 쿠폰',\n",
        "                        '3개월', '창립기획', '단독모델', '스태킹설치포함', '자동먼지비움', '무빙키트' , '공기살균', '쇼핑몰', '상의5벌+하의1벌', '배송!', '외장', '외장그래픽',\n",
        "                        '전자동', '오프라인', '온라인', '전용', '6인용', '3인용', '개별구매불가 본체만구매-자동취소', '미세먼지극복', '병렬설치', '비밀', '앵글설치포함']"
      ],
      "metadata": {
        "id": "qCaRX7D71ayb"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "기존 제품명 리스트에 비해 수는 대폭 줄일 수 있었음. (형태소 추출을 통해 띄어쓰기 구분이 필요없어짐)\n",
        "\n",
        "다만 한국어의 형태소의 특징과 더불어 제품명이 대부분 합성어인점, 많은 신조어, 형태소 구분 라이브러리 자체의 문제가 합쳐져 100% 원하는 형태의 추출은 힘든 상황\n",
        "\n",
        "현재 형태소 화이트리스트 작성 (원하는 단어는 하나의 형태소 취급)을 통해 임시방편 해결은 가능함\n",
        "\n",
        "기존 불용어와 색상리스트는 재활용하였음"
      ],
      "metadata": {
        "id": "Nh3PJHOcAoV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exception functions"
      ],
      "metadata": {
        "id": "kikqoN2hpm3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# exceptions.py\n",
        "\n",
        "def handle_process_text_exceptions(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        try:\n",
        "            return func(*args, **kwargs)\n",
        "        except AttributeError:\n",
        "            print(\"MeCab object 'mecab' is not defined or doesn't have 'morphs' method\")\n",
        "            return \"\", \"\"\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred in process_text: {str(e)}\")\n",
        "            return \"\", \"\"\n",
        "    return wrapper\n",
        "\n",
        "def handle_find_storage_exceptions(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        try:\n",
        "            return func(*args, **kwargs)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred in find_storage: {str(e)}\")\n",
        "            return 'N/A', 'N/A'\n",
        "    return wrapper"
      ],
      "metadata": {
        "id": "6V8KDEgsplyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definition"
      ],
      "metadata": {
        "id": "8nJJzoW4bVqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def advanced_cleaning(descriptions, stopwords, serial_numbers, color_list):\n",
        "    if isinstance(descriptions, str):\n",
        "        descriptions = [descriptions]\n",
        "\n",
        "    stopwords_set = set(stopwords)\n",
        "    stopwords_pattern = re.compile(r'\\b(' + '|'.join(re.escape(sw) for sw in stopwords_set) + r')\\b', re.IGNORECASE)\n",
        "\n",
        "    cleaned_descriptions = []\n",
        "\n",
        "    for description, serial in zip(descriptions, serial_numbers):\n",
        "        # Remove serial number\n",
        "        if serial:\n",
        "            description = re.sub(re.escape(serial), '', description)\n",
        "        if '점]' in description:\n",
        "            description = description.split('점]')[-1]\n",
        "\n",
        "        # 용량 정보 추출\n",
        "        storage = find_storage1(description)\n",
        "\n",
        "        # 색상 정보 추출\n",
        "        color = color_extraction1(description, color_list)\n",
        "\n",
        "        # 불용어 및 특수 문자 제거 (2번 파트의 로직 적용)\n",
        "        description = re.sub(r'[^A-Za-z0-9ㄱ-ㅎㅏ-ㅣ가-힣+\\s²]', ' ', description)\n",
        "        description = stopwords_pattern.sub('', description)\n",
        "\n",
        "        # 추가 정제: 연속된 공백 제거\n",
        "        description = re.sub(r'\\s+', ' ', description).strip()\n",
        "\n",
        "        # 추출된 정보와 함께 정제된 설명 저장\n",
        "        cleaned_descriptions.append({\n",
        "            'cleaned_text': description,\n",
        "            'storage': storage,\n",
        "            'color': color\n",
        "        })\n",
        "\n",
        "    return cleaned_descriptions if len(cleaned_descriptions) > 1 else cleaned_descriptions[0]\n",
        "\n",
        "def find_storage1(text):\n",
        "    if not isinstance(text, str):\n",
        "        raise TypeError(\"Input 'text' must be a string\")\n",
        "    storage_pattern = r'(\\d+)(GB|gb|TB|tb)'\n",
        "    match = re.search(storage_pattern, text, re.IGNORECASE)\n",
        "    if match:\n",
        "        storage_value = int(match.group(1))\n",
        "        storage_unit = match.group(2).upper()\n",
        "        if storage_unit == 'GB' and storage_value < 64:\n",
        "            return 'N/A'\n",
        "        else:\n",
        "            return f'{storage_value}{storage_unit}'\n",
        "    else:\n",
        "        return 'N/A'\n",
        "\n",
        "def color_extraction1(text, color_list):\n",
        "    color_pattern = r'\\b(' + '|'.join(re.escape(color) for color in color_list) + r')\\b'\n",
        "    match = re.search(color_pattern, text, re.IGNORECASE)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return 'N/A'\n",
        "\n",
        "\n",
        "# def find_storage1(text):\n",
        "#     if not isinstance(text, str):\n",
        "#         raise TypeError(\"Input 'text' must be a string\")\n",
        "#     storage_pattern = r'(?:\\(|\\[|\\{)\\s*(\\d+)(GB|gb|TB|tb)\\s*(?:\\)|\\]|\\})'\n",
        "#     match = re.search(storage_pattern, text, re.IGNORECASE)\n",
        "#     if match:\n",
        "#         storage_value = int(match.group(1))\n",
        "#         storage_unit = match.group(2).upper()\n",
        "#         if storage_unit == 'GB' and storage_value < 64:\n",
        "#             return 'N/A'\n",
        "#         else:\n",
        "#             return f'{storage_value}{storage_unit}'\n",
        "#     else:\n",
        "#         return 'N/A'\n",
        "\n",
        "# def color_extraction1(text, color_list):\n",
        "#     color_pattern = r'(?:\\(|\\[|\\{)\\s*(' + '|'.join(re.escape(color) for color in color_list) + r')\\s*(?:\\)|\\]|\\})'\n",
        "#     match = re.search(color_pattern, text, re.IGNORECASE)\n",
        "#     if match:\n",
        "#         return match.group(1)\n",
        "#     else:\n",
        "#         return 'N/A'"
      ],
      "metadata": {
        "id": "nRatDdyYFYan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKfxICKZWBCc"
      },
      "outputs": [],
      "source": [
        "def cleaning_general1(descriptions, stopwords, serial_numbers):\n",
        "    if isinstance(descriptions, str):\n",
        "        descriptions = [descriptions]\n",
        "\n",
        "    stopwords_set = set(stopwords)\n",
        "    stopwords_pattern = re.compile(r'\\b(' + '|'.join(re.escape(sw) for sw in stopwords_set) + r')\\b', re.IGNORECASE)\n",
        "\n",
        "    cleaned_descriptions = []\n",
        "\n",
        "    for description, serial in zip(descriptions, serial_numbers):\n",
        "        # Remove serial number\n",
        "        if serial:\n",
        "            description = re.sub(re.escape(serial), '', description)\n",
        "\n",
        "        if '점]' in description:\n",
        "          cleaned_description = description.split('점]')[-1]\n",
        "\n",
        "        # Remove non-alphanumeric, non-Korean characters, except for spaces, +, and ²\n",
        "        cleaned_description = re.sub(r'[^A-Za-z0-9ㄱ-ㅎㅏ-ㅣ가-힣+\\s²]', ' ', description)\n",
        "\n",
        "        # Remove stopwords\n",
        "        cleaned_description = stopwords_pattern.sub('', cleaned_description)\n",
        "\n",
        "        # Remove extra spaces\n",
        "        cleaned_description = re.sub(r'\\s+', ' ', cleaned_description).strip()\n",
        "\n",
        "        cleaned_descriptions.append(cleaned_description)\n",
        "\n",
        "    return cleaned_descriptions if len(cleaned_descriptions) > 1 else cleaned_descriptions[0]\n",
        "\n",
        "# ETC 제목 추출 함수\n",
        "@handle_process_text_exceptions\n",
        "def title_ETC(description):\n",
        "    name = description\n",
        "    return name\n",
        "\n",
        "\n",
        "# IT 제목 추출 함수\n",
        "@handle_process_text_exceptions\n",
        "def process_text(morphs, title_list):\n",
        "    if not isinstance(morphs, list):\n",
        "        raise TypeError(\"Input 'morphs' must be a list\")\n",
        "    if not isinstance(title_list, list):\n",
        "        raise TypeError(\"Input 'title_list' must be a list\")\n",
        "\n",
        "    title = []\n",
        "    i = 0\n",
        "    while i < len(morphs):\n",
        "        if morphs[i] in title_list:\n",
        "            title.append(morphs[i])\n",
        "            i += 1\n",
        "            if i < len(morphs) and morphs[i].isdigit():\n",
        "                title.append(morphs[i])\n",
        "                i += 1\n",
        "        else:\n",
        "            i += 1\n",
        "\n",
        "    return ''.join(title).strip()\n",
        "\n",
        "@handle_find_storage_exceptions\n",
        "def find_storage(morphs):\n",
        "    if not isinstance(morphs, list):\n",
        "        raise TypeError(\"Input 'morphs' must be a list\")\n",
        "    storage = 'N/A'\n",
        "    for word in morphs:\n",
        "        if not isinstance(word, str):\n",
        "            continue\n",
        "        if word in ['64', '128', '256', '512', '1024']:\n",
        "            storage = f'{word}GB'\n",
        "        elif word in ['1TB', '2TB']:\n",
        "            storage = word\n",
        "    return storage\n",
        "\n",
        "# Attribute call Func\n",
        "def get_product_type(attributes, product_type_dict):\n",
        "    def classify_type(attribute):\n",
        "        if attribute in product_type_dict:\n",
        "            return product_type_dict[attribute]\n",
        "        else:\n",
        "            return 'ETC'\n",
        "\n",
        "    return attributes.map(classify_type)\n",
        "\n",
        "# Color Extract Func\n",
        "def color_extraction(morphs,color_list):\n",
        "  color = next((word for word in morphs if word in color_list), 'N/A')\n",
        "  return color\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "설명\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "***cleaning_general1 함수:***\n",
        "\n",
        "설명 텍스트를 정제하는 함수입니다.\n",
        "시리얼 번호 제거, 특수 문자 제거, 불용어 제거, 그리고 여분의 공백을 제거합니다.\n",
        "'점]' 이후의 텍스트만 남기는 기능도 있습니다.\n",
        "\n",
        "형태소 추출 이전 필요없는 텍스트를 제거해서 전반적인 처리 속도를 높였습니다.\n",
        "\n",
        "주요 기능:\n",
        "\n",
        "1. 시리얼 번호 제거\n",
        "\n",
        "2. '점]' 이후의 텍스트만 추출 >> [매장/상태] 로 표기된 전시상품 표기 제거를 위함\n",
        "\n",
        "3. 알파벳, 숫자, 한글, '+', '²'를 제외한 모든 문자 제거\n",
        "\n",
        "4. 불용어(stopwords) 제거\n",
        "\n",
        "5. 여분의 공백 제거\n",
        "\n",
        "\n",
        "현재 이슈:\n",
        "\n",
        "1. 실제 시리얼번호와 제목에 있는 시리얼이 완전일치는 아님 (시리얼 번호 일부만 삽입돼 있음)\n",
        "2. 그로인해 시리얼 번호 제거가 완전히 이루어지고 있지 않은 상황 (IT제품에서)\n",
        "\n",
        "***title_ETC 함수:***\n",
        "\n",
        "비IT 제품의 제목을 생성하는 함수입니다.\n",
        "\n",
        "비IT 제품들의 제목 다양성이 높아 IT제품 제목 추출하는 방식을 쓰기엔 제약이 있습니다.\n",
        "\n",
        "제조사 코드(회사명)와 제품 유형을 조합하여 제목을 만듭니다.\n",
        "\n",
        "현재는 함수에서 바로 엑셀 데이터를 가져오지만 추후에 변수로 지정해서 불러오는 방식으로 바꿀 예정입니다.\n",
        "\n",
        "문제점:\n",
        "\n",
        "1. 이 방식의 경우 가전제품이 어떤 브랜드인지 파악은 불가능 >> 자세한 제품의 브랜드 및 제목을 알기 위해선 추가적으로 엑셀에서 찾아봐야함\n",
        "2. IT제품중에서도 이 함수를 쓰는 경우가 있음. 주로 마이너한 브랜드, 제품명 리스트에 없는경우 이 함수를 쓰도록 되어있음 (보편적인 처리를 위해서).\n",
        "\n",
        "***process_text 함수:***\n",
        "\n",
        "IT 제품의 제목을 추출하는 함수입니다.\n",
        "주어진 형태소 목록에서 title_list에 있는 단어와 그 뒤의 숫자를 찾아 제목을 만듭니다.\n",
        "\n",
        "주요 기능:\n",
        "\n",
        "1. 주어진 형태소 목록에서 title_list에 포함된 단어 추출\n",
        "2. 추출된 단어 뒤의 숫자도 함께 포함\n",
        "\n",
        "\n",
        "***find_storage 함수:***\n",
        "\n",
        "제품의 저장 용량을 찾는 함수입니다.\n",
        "64GB부터 2TB까지의 용량을 인식할 수 있습니다.\n",
        "['64', '128', '256', '512', '1024'] and 1TB. 2TB\n",
        "\n",
        "***get_product_type 함수:***\n",
        "\n",
        "제품의 유형을 분류하는 함수입니다.\n",
        "product_type_dict를 사용하여 'IT' 또는 'ETC'로 분류합니다.\n",
        "기능: product_type_dict를 사용하여 'IT' 또는 'ETC'로 분류\n",
        "\n",
        "***color_extraction 함수:***\n",
        "\n",
        "제품의 색상을 추출하는 함수입니다.\n",
        "주어진 형태소 목록에서 color_list에 있는 색상을 찾습니다.\n",
        "\n",
        "주요 기능: 주어진 형태소 목록에서 color_list에 포함된 색상 찾기\n",
        "특징: 색상을 찾지 못할 경우 'N/A' 반환"
      ],
      "metadata": {
        "id": "jJqKSwhw_YbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataframe(df, title, product_type_dict, stopwords, color_list, attribute, serial_numbers):\n",
        "    filtered_text = cleaning_general1(title, stopwords, serial_numbers)  # Data Cleaning\n",
        "    extracted_title = []\n",
        "    extracted_color = []\n",
        "    extracted_storage = []\n",
        "    mecab = Mecab()\n",
        "\n",
        "        # Get product types for all items at once\n",
        "    product_types = get_product_type(attribute, product_type_dict)\n",
        "\n",
        "    for index, (text, product_type) in enumerate(zip(filtered_text, product_types)):\n",
        "        if product_type == 'IT':\n",
        "            mecabmorphs = mecab.morphs(text)  # 형태소 추출\n",
        "            # 제목, 색상, 용량 형태소 추출\n",
        "            extracted_title.append(process_text(mecabmorphs, product_title) or title_ETC(filtered_text[index]))\n",
        "            extracted_color.append(color_extraction(mecabmorphs, color_list))\n",
        "            extracted_storage.append(find_storage(mecabmorphs))\n",
        "        else:\n",
        "            extracted_title.append(title_ETC(['cleaned_text']))\n",
        "            extracted_color.append('N/A')\n",
        "            extracted_storage.append('N/A')\n",
        "\n",
        "\n",
        "    # Convert lists to Series\n",
        "    extracted_title = pd.Series(extracted_title)\n",
        "    extracted_color = pd.Series(extracted_color)\n",
        "    extracted_storage = pd.Series(extracted_storage)\n",
        "    extracted_type = pd.Series(product_types)\n",
        "    extracted_classification = pd.Series(df[\"TYPE__CODE\"])\n",
        "    original_title = pd.Series(df[\"DESCRIPTION\"])\n",
        "    cleaned_df = pd.DataFrame({\n",
        "        'TITLE': extracted_title,\n",
        "        'COLOR': extracted_color,\n",
        "        'STORAGE': extracted_storage,\n",
        "        'Type': extracted_type,\n",
        "        'Classification': extracted_classification,\n",
        "        'Original': original_title})\n",
        "    return cleaned_df"
      ],
      "metadata": {
        "id": "HUxcJ-tEF5fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataframe_advanced(df, title, product_type_dict, stopwords, color_list, attribute, serial_numbers):\n",
        "    cleaned_data = advanced_cleaning(title, stopwords, serial_numbers, color_list)  # Advanced Data Cleaning\n",
        "    extracted_title = []\n",
        "    extracted_color = []\n",
        "    extracted_storage = []\n",
        "    mecab = Mecab()\n",
        "\n",
        "    # Get product types for all items at once\n",
        "    product_types = get_product_type(attribute, product_type_dict)\n",
        "\n",
        "    for index, (data, product_type) in enumerate(zip(cleaned_data, product_types)):\n",
        "        if product_type == 'IT':\n",
        "            mecabmorphs = mecab.morphs(data['cleaned_text'])  # 형태소 추출\n",
        "            # 제목, 색상, 용량 형태소 추출\n",
        "            extracted_title.append(process_text(mecabmorphs, product_title) or title_ETC(data['cleaned_text']))\n",
        "            extracted_color.append(data['color'])\n",
        "            extracted_storage.append(data['storage'])\n",
        "        else:\n",
        "            extracted_title.append(title_ETC(data['cleaned_text']))\n",
        "            extracted_color.append('N/A')\n",
        "            extracted_storage.append('N/A')\n",
        "\n",
        "    # Convert lists to Series\n",
        "    extracted_title = pd.Series(extracted_title)\n",
        "    extracted_color = pd.Series(extracted_color)\n",
        "    extracted_storage = pd.Series(extracted_storage)\n",
        "    extracted_type = pd.Series(product_types)\n",
        "    extracted_classification = pd.Series(df[\"TYPE__CODE\"])\n",
        "    original_title = pd.Series(df[\"DESCRIPTION\"])\n",
        "    cleaned_df = pd.DataFrame({\n",
        "        'Original': original_title,\n",
        "        'TITLE': extracted_title,\n",
        "        'COLOR': extracted_color,\n",
        "        'STORAGE': extracted_storage,\n",
        "        'Type': extracted_type,\n",
        "        'Classification': extracted_classification\n",
        "        })\n",
        "    return cleaned_df"
      ],
      "metadata": {
        "id": "poKWeUlyEb1v"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create_dataframe 함수:\n",
        "\n",
        "데이터 전처리:\n",
        "\n",
        "cleaning_general1 함수를 사용하여 텍스트 데이터를 정제합니다.\n",
        "\n",
        "\n",
        "제품 유형 분류:\n",
        "\n",
        "get_product_type 함수를 사용하여 모든 아이템의 제품 유형을 한 번에 가져옵니다.\n",
        "\n",
        "\n",
        "데이터 추출 루프:\n",
        "\n",
        "각 아이템에 대해 제품 유형에 따라 다르게 처리합니다.\n",
        "\n",
        "IT 제품의 경우:\n",
        "\n",
        "MeCab을 사용하여 형태소 분석을 수행합니다.\n",
        "process_text 함수로 제목을 추출하고, 실패 시 title_ETC 함수를 사용합니다.\n",
        "색상과 저장 용량 정보를 추출합니다.\n",
        "\n",
        "\n",
        "비IT 제품의 경우:\n",
        "\n",
        "title_ETC 함수로 제목을 생성합니다.\n",
        "색상과 저장 용량은 'N/A'로 설정합니다.\n",
        "\n",
        "\n",
        "데이터프레임 생성:\n",
        "\n",
        "추출된 정보를 pandas Series로 변환합니다.\n",
        "최종적으로 모든 정보를 포함하는 새로운 데이터프레임을 생성합니다."
      ],
      "metadata": {
        "id": "1uam2Xbc_i2I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add User Dictionary for Mecab"
      ],
      "metadata": {
        "id": "NdMMOX0YScuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/mecab-ko-dic-2.1.1-20180720"
      ],
      "metadata": {
        "id": "zCBnSR1BSk90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "263fe3b5-75c9-4ac5-9c37-c050db86ec90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mecab-ko-dic-2.1.1-20180720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jamo"
      ],
      "metadata": {
        "id": "R7yZsbUISzfA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f29d70fa-7721-4f97-dd5e-d11d58609e06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jamo\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: jamo\n",
            "Successfully installed jamo-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jamo import h2j, j2hcj\n",
        "\n",
        "\n",
        "def get_jongsung_TF(sample_text):\n",
        "    sample_text_list = list(sample_text)\n",
        "    last_word = sample_text_list[-1]\n",
        "    last_word_jamo_list = list(j2hcj(h2j(last_word)))\n",
        "    last_jamo = last_word_jamo_list[-1]\n",
        "\n",
        "    jongsung_TF = \"T\"\n",
        "\n",
        "    if last_jamo in ['ㅏ', 'ㅑ', 'ㅓ', 'ㅕ', 'ㅗ', 'ㅛ', 'ㅜ', 'ㅠ', 'ㅡ', 'ㅣ', 'ㅘ', 'ㅚ', 'ㅙ', 'ㅝ', 'ㅞ', 'ㅢ', 'ㅐ,ㅔ', 'ㅟ', 'ㅖ', 'ㅒ']:\n",
        "        jongsung_TF = \"F\"\n",
        "\n",
        "    return jongsung_TF\n",
        "\n",
        "def make_user_dic_csv(morpheme_type, word_list, user_dic_file_name):\n",
        "  file_data = []\n",
        "\n",
        "  for word, score in word_list:\n",
        "    jongsung_TF = get_jongsung_TF(word)\n",
        "\n",
        "    line = f\"{word},,,{score},{morpheme_type},*,{jongsung_TF},{word},*,*,*,*,*\\n\"\n",
        "    # 단어, left-ID, right-ID, Weight, 품사, 의미분류, 종성유무, 읽기, 타입, 첫번째품사, 마지막품사, 표현\n",
        "    # https://openuiz.blogspot.com/2018/12/mecab-ko-dic.html\n",
        "\n",
        "    file_data.append(line)\n",
        "\n",
        "  with open(\"./user-dic/user-nnp.csv\", 'w', encoding='utf-8') as f:\n",
        "    for line in file_data:\n",
        "      f.write(line)"
      ],
      "metadata": {
        "id": "-8I8UdmkS1JN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_list = [('1TB', 0), ('2TB', 0),  ('미패드',0), ('Wi-Fi',0), ('다크레드',0), ('스타라이트',0), ('그라파이트', 0), ('미드나이트', 0), ('블루', 0), ('뮤패드', 0),\n",
        "              ('미스티라일락', 0), ('보타닉그린',0), ('코튼플라워', 0),('시나모롤',0), ('그레이그린', 0)]\n",
        "\n",
        "#  단어 추가 방법: ('원하는단어형태', 0) 를 대괄호 안에 넣어주세요. ( )엔 하나의 단어만 사용해주세요.\n",
        "#  Method to add a word: Insert ('desired_word_form', 0) inside the bracket. Use only one word inside the parentheses.\n",
        "#  Example) word_list = [('1TB', 0), ('2TB', 0)]\n",
        "\n",
        "make_user_dic_csv(morpheme_type=\"NNP\", word_list=word_list, user_dic_file_name='user-nnp.csv')\n",
        "\n",
        "with open(\"./user-dic/user-nnp.csv\", 'r', encoding='utf-8') as f:\n",
        "  file_new = f.readlines()\n",
        "file_new\n",
        "\n",
        "!bash autogen.sh\n",
        "!make\n",
        "!sudo make install\n",
        "!bash tools/add-userdic.sh"
      ],
      "metadata": {
        "id": "MswYRu27S18M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59c3e0c3-015e-4f33-e6ad-a9a517540cdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in current directory for macros.\n",
            "configure.ac:2: warning: AM_INIT_AUTOMAKE: two- and three-arguments forms are deprecated.\n",
            "./lib/autoconf/general.m4:2434: AC_DIAGNOSE is expanded from...\n",
            "aclocal.m4:139: AM_INIT_AUTOMAKE is expanded from...\n",
            "configure.ac:2: the top level\n",
            "configure.ac:56: warning: AC_OUTPUT should be used without arguments.\n",
            "configure.ac:56: You should run autoupdate.\n",
            "configure.ac:2: warning: AM_INIT_AUTOMAKE: two- and three-arguments forms are deprecated.  For more info, see:\n",
            "configure.ac:2: https://www.gnu.org/software/automake/manual/automake.html#Modernize-AM_005fINIT_005fAUTOMAKE-invocation\n",
            "/bin/bash ./config.status --recheck\n",
            "running CONFIG_SHELL=/bin/bash /bin/bash ./configure --no-create --no-recursion\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "/content/mecab-ko-dic-2.1.1-20180720/missing: Unknown `--is-lightweight' option\n",
            "Try `/content/mecab-ko-dic-2.1.1-20180720/missing --help' for more information\n",
            "configure: WARNING: 'missing' script is too old or missing\n",
            "checking for a race-free mkdir -p... /usr/bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking whether make supports nested variables... yes\n",
            "checking for mecab-config... /usr/local/bin/mecab-config\n",
            "checking that generated files are newer than configure... done\n",
            "configure: creating ./config.status\n",
            " /bin/bash ./config.status\n",
            "config.status: creating Makefile\n",
            "/usr/local/libexec/mecab/mecab-dict-index -d . -o . -f UTF-8 -t UTF-8\n",
            "reading ./unk.def ... 13\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./Person-actor.csv ... 99230\n",
            "reading ./NP.csv ... 342\n",
            "reading ./Place.csv ... 30303\n",
            "reading ./NorthKorea.csv ... 3\n",
            "reading ./XR.csv ... 3637\n",
            "reading ./Preanalysis.csv ... 5\n",
            "reading ./EP.csv ... 51\n",
            "reading ./IC.csv ... 1305\n",
            "reading ./MM.csv ... 453\n",
            "reading ./EF.csv ... 1820\n",
            "reading ./MAG.csv ... 14242\n",
            "reading ./VX.csv ... 125\n",
            "reading ./NNP.csv ... 2371\n",
            "reading ./Place-station.csv ... 1145\n",
            "reading ./Person.csv ... 196459\n",
            "reading ./VCP.csv ... 9\n",
            "reading ./NR.csv ... 482\n",
            "reading ./Inflect.csv ... 44820\n",
            "reading ./VA.csv ... 2360\n",
            "reading ./VCN.csv ... 7\n",
            "reading ./MAJ.csv ... 240\n",
            "reading ./NNG.csv ... 208524\n",
            "reading ./EC.csv ... 2547\n",
            "reading ./Foreign.csv ... 11690\n",
            "reading ./NNBC.csv ... 677\n",
            "reading ./Wikipedia.csv ... 36762\n",
            "reading ./Hanja.csv ... 125750\n",
            "reading ./Symbol.csv ... 16\n",
            "reading ./XSN.csv ... 124\n",
            "reading ./XSA.csv ... 19\n",
            "reading ./XPN.csv ... 83\n",
            "reading ./CoinedWord.csv ... 148\n",
            "reading ./ETN.csv ... 14\n",
            "reading ./VV.csv ... 7331\n",
            "reading ./Group.csv ... 3176\n",
            "reading ./NNB.csv ... 140\n",
            "reading ./Place-address.csv ... 19301\n",
            "reading ./XSV.csv ... 23\n",
            "reading ./ETM.csv ... 133\n",
            "reading ./J.csv ... 416\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 3822x2693\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "echo To enable dictionary, rewrite /usr/local/etc/mecabrc as \\\"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\\\"\n",
            "To enable dictionary, rewrite /usr/local/etc/mecabrc as \"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\"\n",
            "make[1]: Entering directory '/content/mecab-ko-dic-2.1.1-20180720'\n",
            "make[1]: Nothing to be done for 'install-exec-am'.\n",
            " /usr/bin/mkdir -p '/usr/local/lib/mecab/dic/mecab-ko-dic'\n",
            " /usr/bin/install -c -m 644 model.bin matrix.bin char.bin sys.dic unk.dic left-id.def right-id.def rewrite.def pos-id.def dicrc '/usr/local/lib/mecab/dic/mecab-ko-dic'\n",
            "make[1]: Leaving directory '/content/mecab-ko-dic-2.1.1-20180720'\n",
            "generating userdic...\n",
            "nnp.csv\n",
            "/content/mecab-ko-dic-2.1.1-20180720/tools/../model.def is not a binary model. reopen it as text mode...\n",
            "reading /content/mecab-ko-dic-2.1.1-20180720/tools/../user-dic/nnp.csv ... \n",
            "done!\n",
            "person.csv\n",
            "/content/mecab-ko-dic-2.1.1-20180720/tools/../model.def is not a binary model. reopen it as text mode...\n",
            "reading /content/mecab-ko-dic-2.1.1-20180720/tools/../user-dic/person.csv ... \n",
            "done!\n",
            "place.csv\n",
            "/content/mecab-ko-dic-2.1.1-20180720/tools/../model.def is not a binary model. reopen it as text mode...\n",
            "reading /content/mecab-ko-dic-2.1.1-20180720/tools/../user-dic/place.csv ... \n",
            "done!\n",
            "user-nnp.csv\n",
            "/content/mecab-ko-dic-2.1.1-20180720/tools/../model.def is not a binary model. reopen it as text mode...\n",
            "reading /content/mecab-ko-dic-2.1.1-20180720/tools/../user-dic/user-nnp.csv ... \n",
            "done!\n",
            "test -z \"model.bin matrix.bin char.bin sys.dic unk.dic\" || rm -f model.bin matrix.bin char.bin sys.dic unk.dic\n",
            "/usr/local/libexec/mecab/mecab-dict-index -d . -o . -f UTF-8 -t UTF-8\n",
            "reading ./unk.def ... 13\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./Person-actor.csv ... 99230\n",
            "reading ./NP.csv ... 342\n",
            "reading ./Place.csv ... 30303\n",
            "reading ./NorthKorea.csv ... 3\n",
            "reading ./XR.csv ... 3637\n",
            "reading ./Preanalysis.csv ... 5\n",
            "reading ./EP.csv ... 51\n",
            "reading ./IC.csv ... 1305\n",
            "reading ./MM.csv ... 453\n",
            "reading ./EF.csv ... 1820\n",
            "reading ./MAG.csv ... 14242\n",
            "reading ./VX.csv ... 125\n",
            "reading ./user-place.csv ... 2\n",
            "reading ./NNP.csv ... 2371\n",
            "reading ./Place-station.csv ... 1145\n",
            "reading ./Person.csv ... 196459\n",
            "reading ./VCP.csv ... 9\n",
            "reading ./NR.csv ... 482\n",
            "reading ./Inflect.csv ... 44820\n",
            "reading ./VA.csv ... 2360\n",
            "reading ./VCN.csv ... 7\n",
            "reading ./user-user-nnp.csv ... 15\n",
            "reading ./user-nnp.csv ... 2\n",
            "reading ./MAJ.csv ... 240\n",
            "reading ./NNG.csv ... 208524\n",
            "reading ./EC.csv ... 2547\n",
            "reading ./Foreign.csv ... 11690\n",
            "reading ./NNBC.csv ... 677\n",
            "reading ./Wikipedia.csv ... 36762\n",
            "reading ./Hanja.csv ... 125750\n",
            "reading ./Symbol.csv ... 16\n",
            "reading ./XSN.csv ... 124\n",
            "reading ./XSA.csv ... 19\n",
            "reading ./XPN.csv ... 83\n",
            "reading ./CoinedWord.csv ... 148\n",
            "reading ./user-person.csv ... 1\n",
            "reading ./ETN.csv ... 14\n",
            "reading ./VV.csv ... 7331\n",
            "reading ./Group.csv ... 3176\n",
            "reading ./NNB.csv ... 140\n",
            "reading ./Place-address.csv ... 19301\n",
            "reading ./XSV.csv ... 23\n",
            "reading ./ETM.csv ... 133\n",
            "reading ./J.csv ... 416\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 3822x2693\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "echo To enable dictionary, rewrite /usr/local/etc/mecabrc as \\\"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\\\"\n",
            "To enable dictionary, rewrite /usr/local/etc/mecabrc as \"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Execution"
      ],
      "metadata": {
        "id": "9kTFSuQ_ZKOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "serial_num = df[\"ATTRIBUTES__MODEL_NUMBER__VALUE__KR\"]\n",
        "title = df[\"DESCRIPTION\"]\n",
        "attributes = df['TYPE__CODE']\n",
        "# Filtered_DF = create_dataframe(df, title, product_type_dict, general_stopwords_list, color_list,attributes, serial_num)\n",
        "Filtered_DF = create_dataframe_advanced(df, title, product_type_dict, general_stopwords_list, color_list,attributes, serial_num)\n",
        "Filtered_DF.to_excel('Filtered_DF.xlsx', index=False)\n",
        "# files.download('Filtered_DF.xlsx')\n"
      ],
      "metadata": {
        "id": "FBVyShnUrFxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    # 대문자로 변환\n",
        "    return text.upper()\n",
        "\n",
        "def group_similar_products(product_names, threshold):\n",
        "    preprocessed_names = [preprocess(name) for name in product_names]\n",
        "    groups = []\n",
        "\n",
        "    for i, name in enumerate(preprocessed_names):\n",
        "        if not groups:\n",
        "            groups.append([product_names[i]])\n",
        "        else:\n",
        "            best_match = process.extractOne(name, [preprocess(g[0]) for g in groups], scorer=fuzz.token_sort_ratio)\n",
        "            if best_match[1] >= threshold:\n",
        "                groups[best_match[2]].append(product_names[i])\n",
        "            else:\n",
        "                groups.append([product_names[i]])\n",
        "\n",
        "    return groups\n",
        "\n",
        "def select_representative_name(group):\n",
        "    representative_name = process.extractOne(preprocess(group[0]), group, scorer=fuzz.token_sort_ratio)[0]\n",
        "    return representative_name\n"
      ],
      "metadata": {
        "id": "k1fHA7wHRQxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 엑셀 파일 읽어들이기\n",
        "df1 = Filtered_DF\n",
        "product_names = df1['TITLE'].tolist()\n",
        "\n",
        "# Type에 따라 threshold 값 설정\n",
        "it_threshold = 85\n",
        "etc_threshold = 80\n",
        "\n",
        "grouped_products = []\n",
        "grouped_names = []\n",
        "scores = []\n",
        "\n",
        "# IT와 비IT간의 다른 Threshold값 대입 (클리닝 기준이 다르기때문에 적용해봄)\n",
        "for index, row in df1.iterrows():\n",
        "    if row['Type'] == 'IT':\n",
        "        threshold = it_threshold\n",
        "    else:\n",
        "        threshold = etc_threshold\n",
        "\n",
        "    product_name = row['TITLE']\n",
        "    best_match = None\n",
        "    best_score = 0\n",
        "\n",
        "    for group in grouped_products:\n",
        "        representative_name = select_representative_name(group)\n",
        "        score = fuzz.token_sort_ratio(preprocess(product_name), preprocess(representative_name))\n",
        "        if score >= threshold and score > best_score:\n",
        "            best_match = representative_name\n",
        "            best_score = score\n",
        "\n",
        "    if best_match:\n",
        "        if best_score < 100:\n",
        "            grouped_names.append(\"*수정됨* \" + best_match)  # 임계값을 넘겨 수정된 경우 \"*수정됨*\" 추가\n",
        "        else:\n",
        "            grouped_names.append(best_match)\n",
        "        scores.append(best_score)\n",
        "    else:\n",
        "        grouped_products.append([product_name])\n",
        "        grouped_names.append(product_name)\n",
        "        scores.append(100)\n",
        "\n",
        "# 기존 열 업데이트\n",
        "df1['Grouped Name'] = grouped_names\n",
        "df1['Score'] = scores\n",
        "\n",
        "# 새로운 엑셀 파일로 저장\n",
        "df1.to_excel('grouped_products.xlsx', index=False)\n",
        "files.download('grouped_products.xlsx')"
      ],
      "metadata": {
        "id": "d98l-SDmUmgL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "4636eb01-b220-412b-b9db-db366fd8a74d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a844ee15-b04a-48a7-bfdc-e923ab8c10f2\", \"grouped_products.xlsx\", 317539)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Debugging / Testing"
      ],
      "metadata": {
        "id": "68f6pI3XQ0Zr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"  [자급제]모토로라g54[256GB][민트그린]  \"\n",
        "# SM-S921NZAEKOO\n",
        "mecab = Mecab()\n",
        "mecabnouns = mecab.nouns(text)\n",
        "# print(\"Mecab Nouns:\", mecabnouns)\n",
        "print(\"원래 제목: \", text)\n",
        "mecabmorphs = mecab.morphs(text)\n",
        "print(\"Mecab Morphs:\", mecabmorphs)\n",
        "# advanced_cleaning(descriptions, stopwords, serial_numbers, color_list)\n",
        "cleaned_morphs = advanced_cleaning(text, general_stopwords_list,serial_num, color_list)\n",
        "print(\"General Cleaning: \", cleaned_morphs)\n",
        "mecabmorph = mecab.morphs(cleaned_morphs)\n",
        "print(\"Cleaned Mecab Morphs: \", mecabmorph)\n",
        "print(\"Process_Text: \", process_text(mecabmorph, product_title))\n",
        "print(\"Color: \", color_extraction(mecabmorph,color_list))\n",
        "print(\"Storage: \", find_storage(mecabmorph))\n"
      ],
      "metadata": {
        "id": "WxcDO_qGQ5vZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "325e7dd2-a775-49d2-ab52-24739ea49f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원래 제목:    [자급제]모토로라g54[256GB][민트그린]  \n",
            "Mecab Morphs: ['[', '자급', '제', ']', '모토', '로라', 'g', '54', '[', '256', 'GB', ']', '[', '민트', '그린', ']']\n",
            "General Cleaning:  {'cleaned_text': '모토로라g54 256GB 민트그린', 'storage': '256GB', 'color': 'N/A'}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "phrase input should be string, not <class 'dict'>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-6aa1c7798fb6>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcleaned_morphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madvanced_cleaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneral_stopwords_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mserial_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"General Cleaning: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcleaned_morphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmecabmorph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmecab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_morphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cleaned Mecab Morphs: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmecabmorph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Process_Text: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmecabmorph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproduct_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/konlpy/tag/_mecab.py\u001b[0m in \u001b[0;36mmorphs\u001b[0;34m(self, phrase)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;34m\"\"\"Parse phrase to morphemes.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnouns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/konlpy/tag/_mecab.py\u001b[0m in \u001b[0;36mpos\u001b[0;34m(self, phrase, flatten, join)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mjoined\u001b[0m \u001b[0msets\u001b[0m \u001b[0mof\u001b[0m \u001b[0mmorph\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mvalidate_phrase_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/konlpy/tag/_common.py\u001b[0m in \u001b[0;36mvalidate_phrase_inputs\u001b[0;34m(phrase)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \"\"\"\n\u001b[1;32m     19\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"phrase input should be string, not %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: phrase input should be string, not <class 'dict'>"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "qDYLTRK_Ia7t",
        "NdMMOX0YScuF"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}